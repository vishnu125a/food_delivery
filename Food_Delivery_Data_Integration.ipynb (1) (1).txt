{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food Delivery Data Integration Project\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates the complete data integration pipeline for combining three different data sources:\n",
    "1. **orders.pdf** - Transactional order data (PDF format)\n",
    "2. **users.json** - User master data (JSON format)\n",
    "3. **resto.docx** - Restaurant master data (SQL INSERT statements in DOCX)\n",
    "\n",
    "## Objective\n",
    "Create a unified dataset by performing LEFT JOINs:\n",
    "- Orders â†’ Users (on user_id)\n",
    "- Orders â†’ Restaurants (on restaurant_id)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install pdfplumber python-docx pandas numpy -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from docx import Document\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract Orders Data from PDF\n",
    "\n",
    "The orders data is stored in a PDF file containing tabular data. We'll extract it using pdfplumber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“‚ STEP 1: Extracting Orders Data from PDF...\\n\")\n",
    "\n",
    "orders_data = []\n",
    "\n",
    "# Extract tables from all pages\n",
    "with pdfplumber.open('orders.pdf') as pdf:\n",
    "    for page in pdf.pages:\n",
    "        tables = page.extract_tables()\n",
    "        for table in tables:\n",
    "            if table:\n",
    "                for row in table:\n",
    "                    if row:\n",
    "                        orders_data.append(row)\n",
    "\n",
    "# Create DataFrame\n",
    "header = orders_data[0]\n",
    "data = orders_data[1:]\n",
    "\n",
    "# Clean rows to match header length\n",
    "clean_rows = []\n",
    "for row in data:\n",
    "    if not all(cell is None or str(cell).strip() == '' for cell in row):\n",
    "        while len(row) < len(header):\n",
    "            row.append(None)\n",
    "        clean_rows.append(row[:len(header)])\n",
    "\n",
    "orders_df = pd.DataFrame(clean_rows, columns=header)\n",
    "orders_df = orders_df.loc[:, orders_df.columns != '']  # Remove empty columns\n",
    "\n",
    "print(f\"âœ“ Extracted {len(orders_df):,} orders\")\n",
    "print(f\"âœ“ Columns: {', '.join(orders_df.columns)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "orders_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Users Data from JSON\n",
    "\n",
    "User master data is stored in JSON format with user demographics and membership information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“‚ STEP 2: Loading Users Data from JSON...\\n\")\n",
    "\n",
    "with open('users.json', 'r') as f:\n",
    "    users_data = json.load(f)\n",
    "\n",
    "users_df = pd.DataFrame(users_data)\n",
    "\n",
    "print(f\"âœ“ Loaded {len(users_df):,} users\")\n",
    "print(f\"âœ“ Columns: {', '.join(users_df.columns)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "users_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Parse Restaurant Data from DOCX (SQL Format)\n",
    "\n",
    "Restaurant data is stored as SQL INSERT statements in a Word document. We'll parse these statements to extract the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“‚ STEP 3: Parsing Restaurant Data from DOCX (SQL format)...\\n\")\n",
    "\n",
    "doc = Document('resto.docx')\n",
    "sql_text = '\\n'.join([para.text for para in doc.paragraphs])\n",
    "\n",
    "# Parse INSERT statements with proper quote handling\n",
    "insert_pattern = r\"INSERT INTO restaurants VALUES \\(([^)]+)\\);\"\n",
    "matches = re.findall(insert_pattern, sql_text)\n",
    "\n",
    "restaurants = []\n",
    "for match in matches:\n",
    "    # Use regex to split by commas not inside quotes\n",
    "    parts = re.findall(r\"'[^']*'|[^,]+\", match)\n",
    "    parts = [p.strip().strip(\"'\") for p in parts]\n",
    "    \n",
    "    if len(parts) >= 4:\n",
    "        try:\n",
    "            restaurants.append({\n",
    "                'restaurant_id': int(parts[0]),\n",
    "                'restaurant_name': parts[1],\n",
    "                'cuisine': parts[2],\n",
    "                'rating': float(parts[3])\n",
    "            })\n",
    "        except (ValueError, IndexError):\n",
    "            continue\n",
    "\n",
    "resto_df = pd.DataFrame(restaurants)\n",
    "\n",
    "print(f\"âœ“ Parsed {len(resto_df):,} restaurants\")\n",
    "print(f\"âœ“ Columns: {', '.join(resto_df.columns)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "resto_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Data Cleaning and Type Conversion\n",
    "\n",
    "Convert data types to appropriate formats for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”§ STEP 4: Cleaning and Converting Data Types...\\n\")\n",
    "\n",
    "# Clean Orders\n",
    "orders_df['order_id'] = pd.to_numeric(orders_df['order_id'], errors='coerce').astype('Int64')\n",
    "orders_df['user_id'] = pd.to_numeric(orders_df['user_id'], errors='coerce').astype('Int64')\n",
    "orders_df['restaurant_id'] = pd.to_numeric(orders_df['restaurant_id'], errors='coerce').astype('Int64')\n",
    "orders_df['total_amount'] = pd.to_numeric(orders_df['total_amount'], errors='coerce')\n",
    "orders_df['order_date'] = pd.to_datetime(orders_df['order_date'], format='%d-%m-%Y', errors='coerce')\n",
    "\n",
    "# Clean Users\n",
    "users_df['user_id'] = pd.to_numeric(users_df['user_id'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Clean Restaurants\n",
    "resto_df['restaurant_id'] = pd.to_numeric(resto_df['restaurant_id'], errors='coerce').astype('Int64')\n",
    "resto_df['rating'] = pd.to_numeric(resto_df['rating'], errors='coerce')\n",
    "\n",
    "# Remove smart quotes from cuisine\n",
    "resto_df['cuisine'] = resto_df['cuisine'].str.replace('\\u2018', '', regex=False)\n",
    "resto_df['cuisine'] = resto_df['cuisine'].str.replace('\\u2019', '', regex=False)\n",
    "resto_df['cuisine'] = resto_df['cuisine'].str.replace(\"'\", '', regex=False)\n",
    "\n",
    "print(\"âœ“ Data types converted and cleaned\")\n",
    "print(f\"\\nOrders data types:\\n{orders_df.dtypes}\")\n",
    "print(f\"\\nUsers data types:\\n{users_df.dtypes}\")\n",
    "print(f\"\\nRestaurants data types:\\n{resto_df.dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Merge Datasets (LEFT JOIN)\n",
    "\n",
    "Perform left joins to combine all three datasets:\n",
    "1. Orders LEFT JOIN Users (on user_id)\n",
    "2. Result LEFT JOIN Restaurants (on restaurant_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”— STEP 5: Merging Datasets...\\n\")\n",
    "print(\"Strategy: Left Join to retain all orders\")\n",
    "\n",
    "# Merge orders with users\n",
    "merged_df = orders_df.merge(users_df, on='user_id', how='left', suffixes=('', '_user'))\n",
    "print(f\"âœ“ Orders + Users = {len(merged_df):,} records\")\n",
    "\n",
    "# Merge with restaurants\n",
    "final_df = merged_df.merge(resto_df, on='restaurant_id', how='left', suffixes=('', '_resto'))\n",
    "print(f\"âœ“ + Restaurants = {len(final_df):,} records\")\n",
    "\n",
    "print(f\"\\nFinal dataset shape: {final_df.shape}\")\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Create Final Dataset with Derived Columns\n",
    "\n",
    "Add useful derived columns for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“Š STEP 6: Building Final Dataset with Derived Columns...\\n\")\n",
    "\n",
    "# Reorder columns logically\n",
    "column_order = [\n",
    "    'order_id', 'order_date', 'user_id', 'name', 'city', 'membership',\n",
    "    'restaurant_id', 'restaurant_name', 'cuisine', 'rating', 'total_amount'\n",
    "]\n",
    "final_df = final_df[[col for col in column_order if col in final_df.columns]]\n",
    "\n",
    "# Add time-based derived columns\n",
    "final_df['year'] = final_df['order_date'].dt.year\n",
    "final_df['month'] = final_df['order_date'].dt.month\n",
    "final_df['month_name'] = final_df['order_date'].dt.strftime('%B')\n",
    "final_df['day_of_week'] = final_df['order_date'].dt.day_name()\n",
    "final_df['quarter'] = final_df['order_date'].dt.quarter\n",
    "final_df['week_of_year'] = final_df['order_date'].dt.isocalendar().week\n",
    "\n",
    "# Add categorical derived columns\n",
    "final_df['is_weekend'] = final_df['day_of_week'].isin(['Saturday', 'Sunday'])\n",
    "final_df['season'] = final_df['month'].map({\n",
    "    12: 'Winter', 1: 'Winter', 2: 'Winter',\n",
    "    3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
    "    6: 'Summer', 7: 'Summer', 8: 'Summer',\n",
    "    9: 'Fall', 10: 'Fall', 11: 'Fall'\n",
    "})\n",
    "final_df['order_size'] = pd.cut(\n",
    "    final_df['total_amount'],\n",
    "    bins=[0, 300, 600, 900, 2000],\n",
    "    labels=['Small', 'Medium', 'Large', 'Extra Large']\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Created {len(final_df.columns)} columns total\")\n",
    "print(f\"\\nColumn names:\\n{list(final_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ” Data Quality Check:\\n\")\n",
    "print(\"Missing Values:\")\n",
    "for col in final_df.columns:\n",
    "    missing = final_df[col].isna().sum()\n",
    "    if missing > 0:\n",
    "        pct = (missing / len(final_df)) * 100\n",
    "        print(f\"  {col}: {missing} ({pct:.2f}%)\")\n",
    "\n",
    "if final_df.isna().sum().sum() == 0:\n",
    "    print(\"  No missing values found (except expected missing cuisine/rating data)\")\n",
    "\n",
    "print(f\"\\nDataset Info:\")\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Save Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "output_file = 'final_food_delivery_dataset.csv'\n",
    "final_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"âœ… Final dataset saved to: {output_file}\")\n",
    "print(f\"\\nDataset shape: {final_df.shape}\")\n",
    "print(f\"File size: {final_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Dataset Summary and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸ“ˆ Overall Statistics:\")\n",
    "print(f\"   Total Orders:        {len(final_df):,}\")\n",
    "print(f\"   Unique Users:        {final_df['user_id'].nunique():,}\")\n",
    "print(f\"   Unique Restaurants:  {final_df['restaurant_id'].nunique():,}\")\n",
    "print(f\"   Cities:              {', '.join(final_df['city'].unique())}\")\n",
    "print(f\"   Date Range:          {final_df['order_date'].min().date()} to {final_df['order_date'].max().date()}\")\n",
    "print(f\"   Total Revenue:       ${final_df['total_amount'].sum():,.2f}\")\n",
    "print(f\"   Average Order Value: ${final_df['total_amount'].mean():.2f}\")\n",
    "\n",
    "print(\"\\nðŸ™ï¸ Distribution by City:\")\n",
    "city_dist = final_df['city'].value_counts()\n",
    "for city, count in city_dist.items():\n",
    "    pct = (count / len(final_df)) * 100\n",
    "    print(f\"   {city:12s}: {count:,} orders ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\nðŸ‘¥ Distribution by Membership:\")\n",
    "mem_dist = final_df['membership'].value_counts()\n",
    "for mem, count in mem_dist.items():\n",
    "    pct = (count / len(final_df)) * 100\n",
    "    print(f\"   {mem:12s}: {count:,} orders ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\nðŸ½ï¸ Distribution by Cuisine:\")\n",
    "cuisine_dist = final_df['cuisine'].value_counts()\n",
    "for cuisine, count in cuisine_dist.items():\n",
    "    pct = (count / len(final_df)) * 100\n",
    "    print(f\"   {cuisine:12s}: {count:,} orders ({pct:.1f}%)\")\n",
    "missing_cuisine = final_df['cuisine'].isna().sum()\n",
    "if missing_cuisine > 0:\n",
    "    pct = (missing_cuisine / len(final_df)) * 100\n",
    "    print(f\"   {'Missing':12s}: {missing_cuisine:,} orders ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Answer Hackathon Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: How many total orders were placed by users with Gold membership?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_orders = final_df[final_df['membership'] == 'Gold'].shape[0]\n",
    "print(f\"Total orders by Gold members: {gold_orders}\")\n",
    "print(f\"\\nVerification:\")\n",
    "print(final_df['membership'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: What is the total revenue (rounded to nearest integer) generated from orders placed in Hyderabad city?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyderabad_revenue = final_df[final_df['city'] == 'Hyderabad']['total_amount'].sum()\n",
    "print(f\"Total revenue from Hyderabad: ${hyderabad_revenue:,.2f}\")\n",
    "print(f\"Rounded to nearest integer: {round(hyderabad_revenue)}\")\n",
    "\n",
    "print(f\"\\nRevenue by city:\")\n",
    "city_revenue = final_df.groupby('city')['total_amount'].sum().sort_values(ascending=False)\n",
    "for city, revenue in city_revenue.items():\n",
    "    print(f\"  {city}: ${revenue:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: How many distinct users placed at least one order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_users = final_df['user_id'].nunique()\n",
    "print(f\"Number of distinct users who placed at least one order: {distinct_users}\")\n",
    "print(f\"\\nAverage orders per user: {len(final_df)/distinct_users:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: What is the average order value (rounded to 2 decimals) for Gold members?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_avg = final_df[final_df['membership'] == 'Gold']['total_amount'].mean()\n",
    "print(f\"Average order value for Gold members: ${gold_avg:.2f}\")\n",
    "\n",
    "print(f\"\\nComparison by membership:\")\n",
    "membership_stats = final_df.groupby('membership')['total_amount'].agg(['mean', 'count', 'sum'])\n",
    "print(membership_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: How many orders were placed for restaurants with rating â‰¥ 4.5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_rated_orders = final_df[final_df['rating'] >= 4.5].shape[0]\n",
    "print(f\"Orders placed for restaurants with rating â‰¥ 4.5: {high_rated_orders}\")\n",
    "\n",
    "print(f\"\\nOrders by rating range:\")\n",
    "print(f\"  Rating â‰¥ 4.5: {final_df[final_df['rating'] >= 4.5].shape[0]}\")\n",
    "print(f\"  Rating 4.0-4.4: {final_df[(final_df['rating'] >= 4.0) & (final_df['rating'] < 4.5)].shape[0]}\")\n",
    "print(f\"  Rating 3.5-3.9: {final_df[(final_df['rating'] >= 3.5) & (final_df['rating'] < 4.0)].shape[0]}\")\n",
    "print(f\"  Rating < 3.5: {final_df[final_df['rating'] < 3.5].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: How many orders were placed in the top revenue city among Gold members only?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df = final_df[final_df['membership'] == 'Gold']\n",
    "gold_city_revenue = gold_df.groupby('city')['total_amount'].agg(['sum', 'count']).sort_values('sum', ascending=False)\n",
    "\n",
    "print(\"Revenue by city for Gold members:\")\n",
    "print(gold_city_revenue)\n",
    "\n",
    "top_city = gold_city_revenue.index[0]\n",
    "orders_in_top_city = int(gold_city_revenue.loc[top_city, 'count'])\n",
    "\n",
    "print(f\"\\nTop revenue city among Gold members: {top_city}\")\n",
    "print(f\"Number of orders in {top_city}: {orders_in_top_city}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Fill-in-the-Blank Answers\n",
    "\n",
    "1. **The column used to join orders.csv and users.json is**: `user_id`\n",
    "2. **The dataset containing cuisine and rating information is stored in**: `SQL` (or `DOCX`) format\n",
    "3. **The total number of rows in the final merged dataset is**: `10000`\n",
    "4. **If a user has no matching record in users.json, the merged values will be**: `NaN` (or `NULL`)\n",
    "5. **The Pandas function used to combine datasets based on a key is**: `merge`\n",
    "6. **The column membership in the final dataset originates from the**: `users.json` file\n",
    "7. **The join key used to combine orders data with restaurant details is**: `restaurant_id`\n",
    "8. **The column that helps identify the type of food served by a restaurant is**: `cuisine`\n",
    "9. **If a user places multiple orders, their personal details appear**: `multiple` times in the final merged dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook successfully demonstrates:\n",
    "1. âœ… Extracting data from multiple file formats (PDF, JSON, DOCX with SQL)\n",
    "2. âœ… Data cleaning and type conversion\n",
    "3. âœ… Performing LEFT JOINs to create a unified dataset\n",
    "4. âœ… Adding derived columns for enhanced analysis\n",
    "5. âœ… Answering business questions using the integrated dataset\n",
    "\n",
    "The final dataset is ready for comprehensive analysis of:\n",
    "- Order trends over time\n",
    "- User behavior patterns\n",
    "- City-wise performance\n",
    "- Cuisine preferences\n",
    "- Revenue distribution\n",
    "- Seasonality effects\n",
    "- Restaurant ratings impact"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
